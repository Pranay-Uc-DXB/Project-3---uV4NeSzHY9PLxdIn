{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os \n",
    "\n",
    "# Importing all the packages\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import RandomResizedCrop\n",
    "from torchvision.transforms import RandomHorizontalFlip\n",
    "from torchvision.transforms import RandomRotation\n",
    "from torchvision.transforms import Normalize\n",
    "from torchvision.transforms import Resize\n",
    "from torchvision.transforms import transforms\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn import Softmax\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Dropout\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt \n",
    "import argparse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv=['']\n",
    "del sys\n",
    "\n",
    "\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-m\", \"--model\", type=str, default=\"resnet\", choices=[\"vgg\", \"resnet\",\"mobilenet\"], help=\"name of the backbone model\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying mean and SD from imagenet dataset statistics\n",
    "Mean= [0.485, 0.456, 0.406]\n",
    "STD= [0.229, 0.224, 0.225]\n",
    "\n",
    "# Specifying training hyperparameters\n",
    "Image_size=1080\n",
    "Batch_size= 128\n",
    "Pred_batch_size= 4\n",
    "EPOCHS=16\n",
    "LR=0.0001\n",
    "\n",
    "# Determining the device type\n",
    "Device= torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_path=r\"C:\\Users\\97158\\Desktop\\Apziva\\Project 4-MonReader\\images\\testing\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# Defining the dataloader function\n",
    "def get_Dataloader(Dataset, Batch_size, shuffle=True):\n",
    "    dl=DataLoader(Dataset,Batch_size,shuffle=shuffle)\n",
    "    return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "testTransform=Compose([\n",
    "    Resize(Image_size),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=Mean,std=STD)\n",
    "])\n",
    "\n",
    "#Creating test Dataset\n",
    "testDataset=ImageFolder(testing_path,testTransform)\n",
    "\n",
    "# Initializing the test dataset\n",
    "testLoader= get_Dataloader(testDataset,Batch_size=Batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\97158/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "# check if the name of the backbone model is VGG\n",
    "if args[\"model\"] == \"vgg\":\n",
    "\t# load VGG-11 model\n",
    "\tbaseModel = torch.hub.load(\"pytorch/vision:v0.10.0\", \"vgg11\",weights='VGG11_Weights.DEFAULT', skip_validation=True)\n",
    "# otherwise, the backbone model we will be using is a ResNet\n",
    "elif args[\"model\"] == \"resnet\":\n",
    "\t# load ResNet 18 model\n",
    "\tbaseModel = torch.hub.load(\"pytorch/vision:v0.10.0\", \"resnet18\",weights='ResNet18_Weights.DEFAULT', skip_validation=True)\n",
    "elif args['model']=='mobilenet':\n",
    "    basemodel=torch.hub.load('pytorch/vision:v0.10.0','mobilenet_v2',weights='MobileNet_V2_Weights.DEFAULT',skip_validation=True) \t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear, Module, Sequential, Conv2d\n",
    "\n",
    "\n",
    "class Classifier(Module):\n",
    "    def __init__(self, baseModel, numclasses, model):\n",
    "        super().__init__()\n",
    "        self.baseModel = baseModel\n",
    "\n",
    "        if model == 'vgg':\n",
    "            # Extracting the number of input features from the last layer of VGG\n",
    "            num_features = baseModel.classifier[6].out_features\n",
    "            \n",
    "            # Defining the extra layer\n",
    "            self.extra_layer1 = Linear(num_features, 512)  # Assuming 512 output features\n",
    "            self.relu1 = ReLU(inplace=True)\n",
    "            self.extra_layer2=Linear(512,256)\n",
    "            self.relu2=ReLU(inplace=True)\n",
    "            \n",
    "            # Defining the final fully connected layer for classification\n",
    "            self.fc = Linear(256, numclasses)  # Using the output features from the extra layer\n",
    "        elif model=='resnet':\n",
    "            \n",
    "            self.extra_layer=Linear(baseModel.fc.out_features,256)\n",
    "            self.relu=ReLU(inplace=True)\n",
    "\n",
    "            # Defining the final fully connected layer for classification\n",
    "            self.fc=Linear(256,numclasses)\n",
    "\n",
    "        elif model=='mobilenet':\n",
    "\n",
    "            num_features=baseModel.classifier[1].out_features\n",
    "\n",
    "            #Defining extra layer\n",
    "            self.extra_layer1=Linear(num_features,512)\n",
    "            self.relu1 = ReLU(inplace=True)\n",
    "            self.extra_layer2=Linear(512,256)\n",
    "            self.relu2=ReLU(inplace=True)\n",
    "            \n",
    "            # Defining the final fully connected layer for classification\n",
    "            self.fc = Linear(256, numclasses)  # Using the output features from the extra layer\n",
    "\n",
    "\n",
    "        # Softmax layer for classification\n",
    "        self.softmax = Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.baseModel(x)\n",
    "        \n",
    "        # Applying the extra layer and ReLU activation\n",
    "        if 'vgg' in self.baseModel.__class__.__name__.lower():\n",
    "            features = self.extra_layer1(features)\n",
    "            features=self.relu1(features)\n",
    "            features=self.extra_layer2(features)\n",
    "            features = self.relu2(features)\n",
    "\n",
    "        elif 'resnet' in self.baseModel.__class__.__name__.lower():\n",
    "            #Applying the extra layer and ReLu activation\n",
    "            features=self.extra_layer(features)\n",
    "            features=self.relu(features)    \n",
    "\n",
    "        elif 'mobilenet' in self.baseModel.__class__.__name__.lower():  \n",
    "            features = self.extra_layer1(features)\n",
    "            features=self.relu1(features)\n",
    "            features=self.extra_layer2(features)\n",
    "            features = self.relu2(features)\n",
    "\n",
    "        \n",
    "        # Passing the features through the final fully connected layer\n",
    "        logits = self.fc(features)\n",
    "        output=self.softmax(logits)\n",
    "        return output        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining paths to store trained model\n",
    "VGG_Model_path= os.path.join(\"model_output\",\"VGG_model.pth\")\n",
    "RESNET_Model_path= os.path.join(\"model_output\",\"ResNet_model.pth\")\n",
    "MobileNet_Model_path= os.path.join(\"model_output\",\"MobileNet_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the model state and inititalizing the loss function\n",
    "# build the custom model\n",
    "model = Classifier(baseModel=baseModel.to(Device),numclasses=2, model=args['model'])\n",
    "model = model.to(Device)\n",
    "\n",
    "\n",
    "if args['model']=='vgg':\n",
    "    model.load_state_dict(torch.load(VGG_Model_path))\n",
    "elif args['model']=='resnet':\n",
    "    model.load_state_dict(torch.load(RESNET_Model_path))\n",
    "elif args['model']=='mobilenet':\n",
    "    model.load_state_dict(torch.load(MobileNet_Model_path))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   0_notflip       0.53      0.53      0.53       307\n",
      "      1_flip       0.51      0.50      0.50       290\n",
      "\n",
      "    accuracy                           0.52       597\n",
      "   macro avg       0.52      0.52      0.52       597\n",
      "weighted avg       0.52      0.52      0.52       597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "Activation_func=Softmax()\n",
    "\n",
    "#Turning off autograd for testing evaluation\n",
    "with torch.no_grad():\n",
    "\n",
    "# setting the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "# initializing list to store predictions\n",
    "    test_pred=[]\n",
    "\n",
    "# looping over the test set\n",
    "    for (x,y) in testLoader:\n",
    "        x=x.to(Device)\n",
    "\n",
    "# making predictions and adding them to the lisy above\n",
    "        logit=model(x)\n",
    "        #pred=Activation_func(logit)\n",
    "        #test_pred.extend(pred.argmax(axis=1).cpu().numpy())\n",
    "        test_pred.extend(logit.argmax(axis=1).cpu().numpy())\n",
    "        \n",
    "test_targets=np.array(testDataset.targets)\n",
    "train_pred=np.array(test_pred)\n",
    "\n",
    "# generating classification report\n",
    "print(classification_report(test_targets,train_pred,target_names=testDataset.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_func=CrossEntropyLoss()\n",
    "# loss_func.to(Device)\n",
    "\n",
    "# # Initializing Test Data loss \n",
    "# TestCorrect=0\n",
    "# TotalTestLoss=0\n",
    "# soft=Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # Putting the model in evaluation mode with gradients turned off\n",
    "# with torch.no_grad():\n",
    "#     model.eval() \n",
    "\n",
    "#     test_pred=[]\n",
    "\n",
    "# # Looping over the test test and sending it to device\n",
    "#     for (image, targets) in tqdm(testLoader):\n",
    "#         (image,targets)=(image.to(Device),targets.to(Device))\n",
    "\n",
    "#         # Making the predictions and calculating the validation loss\n",
    "        \n",
    "#         logit=model(image)\n",
    "#         loss=loss_func(logit, targets)\n",
    "#         TotalTestLoss += loss.item()\n",
    "\n",
    "\n",
    "#     # Getting predictions and calculating all the correct predictions\n",
    "#         pred=soft(logit)\n",
    "#         test_pred.extend(pred.argmax(axis=1).detach().cpu().numpy())\n",
    "#         TestCorrect += (pred.argmax(dim=-1)== targets).sum().item()\n",
    "\n",
    "\n",
    "# test_targets=np.array(testDataset.targets)\n",
    "# test_pred=np.array(test_pred)\n",
    "\n",
    "# # generating classification report\n",
    "# print(classification_report(test_targets,test_pred,target_names=testDataset.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
